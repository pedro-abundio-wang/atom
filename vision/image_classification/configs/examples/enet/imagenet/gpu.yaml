# Training configuration for ENet trained on CamVid on GPUs.
# Note: This configuration uses a scaled per-replica batch size based on the number of devices.
runtime:
  model_dir: null
  mode: 'train_and_eval'
  distribution_strategy: 'one_device'
  num_gpus: 1
  enable_xla: False
train_dataset:
  name: 'camvid'
  data_dir: null
  builder: 'records'
  split: 'train'
  image_size: 224
  num_classes: 1000
  num_examples: 1281167
  batch_size: 128
  use_per_replica_batch_size: True
  dtype: 'float32'
  mean_subtract: True
  standardize: True
validation_dataset:
  name: 'camvid'
  data_dir: null
  builder: 'records'
  split: 'validation'
  image_size: 224
  num_classes: 1000
  num_examples: 50000
  batch_size: 128
  use_per_replica_batch_size: True
  dtype: 'float32'
  mean_subtract: True
  standardize: True
model:
  model_name: 'enet'
  optimizer:
    name: 'adam'
    momentum: 0.9
    decay: 0.9
    epsilon: 0.001
  learning_rate:
    name: 'exponential'
    initial_lr: 0.1
  loss:
    label_smoothing: 0.1
train:
  resume_checkpoint: True
  epochs: 30
evaluation:
  epochs_between_evals: 1
